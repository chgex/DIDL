{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "acd847c392487aabfa03d14b5dc5b2ae233417a28e2d9e43c03b69bccff2848e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 5.5 LeNet\n",
    "\n",
    "卷积层：\n",
    "\n",
    "+ 卷积层保留输入形状，使图像的像素在高和宽两个方向上的相关性被保留，从而被有效识别。\n",
    "\n",
    "+ 卷积层使用滑动窗口将同一卷积核不同位置的输入重复计算，避免了参数的尺寸过大。\n",
    "\n",
    "卷积层用来识别图像中的空间模式，比如线条和物体的局部。\n",
    "\n",
    "最大池化层用来降低卷积层对于位置的敏感性。\n",
    "\n",
    "LeNet网络\n",
    "\n",
    "+ LeNet网络使用5\\*5的卷积核，在输出上使用sigmoid激活函数，\n",
    "\n",
    "+ 第一个卷积层的输出通道为6，第二个卷积层的输出通道为16，因为第二个卷积层输入的高和宽要比第一个的输入小。\n",
    "> 增加输出通道是为了使两个卷积层的参数尺寸类似。\n",
    "\n",
    "+ 卷积层输出通道数取决于卷积核的数量，\n",
    "\n",
    "+ 一个卷积层和一个池化层共同构成卷积块，\n",
    "\n",
    "+ 卷积块中的最大池化层的窗口为2\\*2，步幅为2\n",
    "> 池化窗口的大小和步幅大小相同，所以池化层在输入上每次滑动所覆盖的区域互不重叠。\n",
    "\n",
    "+ 一共10个类别，即最后的输出向量维度为10.\n",
    "\n",
    "\n",
    "\n",
    "其它\n",
    "\n",
    "+ LeNet中的卷积层，使用的是conv2d()，二维卷积用于图像数据，对宽度和高度进行卷积。`class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)`\n",
    "\n",
    "+ conv1d()该函数是对文本数据进行卷积，不对高度进行卷积。`class torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import d2l_pytorch as d2l \n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        # 卷积块包含2层：卷积层，激活函数，最大池化，卷积层，激活函数，最大池化\n",
    "        # in_channel=1,out_channle=6,kernelz-size=5\n",
    "        self.conv=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(in_features=16*4*4,out_features=120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=120,out_features=84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=84,out_features=10)\n",
    "        )\n",
    "    def forward(self,img):\n",
    "        feature=self.conv(img)\n",
    "        output=self.fc(feature.view(img.shape[0],-1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LeNet(\n  (conv): Sequential(\n    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n    (1): Sigmoid()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n    (4): Sigmoid()\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=256, out_features=120, bias=True)\n    (1): Sigmoid()\n    (2): Linear(in_features=120, out_features=84, bias=True)\n    (3): Sigmoid()\n    (4): Linear(in_features=84, out_features=10, bias=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "net=LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据和训练数据\n",
    "\n",
    "batch_size=256\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估函数，使支持gpu计算。\n",
    "\n",
    "def evaluate_accuracy(data_iter,net,device=None):\n",
    "    # gpu\n",
    "    if device is None and isinstance(net,torch.nn.Module):\n",
    "        # 如果没有指定device，则使用net的device\n",
    "        device=list(net.parameters())[0].device\n",
    "    # 准确率，总数\n",
    "    acc_sum,n=0.0,0\n",
    "    # with torch.no_grad： disables tracking of gradients in autograd. \n",
    "    # model.eval()： changes the forward() behaviour of the module it is called upon.\n",
    "    with torch.no_grad():\n",
    "        for X,y in data_iter:\n",
    "            if isinstance(net,torch.nn.Module):\n",
    "                # 评估模式，该模式会关闭dropout\n",
    "                net.eval()\n",
    "                # torch.argmax(input, dim, keepdim=False) → LongTensor返回指定维度的最大值的索引。\n",
    "                acc_sum+=( net(X.to(device)).argmax(dim=1) == y.to(device) ).float().sum().cpu().item()\n",
    "            else: # 无GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n+=y.shape[0]\n",
    "    return acc_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数：确保计算使用的数据和模型在同一个内存或显卡上\n",
    "\n",
    "def train(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs):\n",
    "    net=net.to(device)\n",
    "    print('training on ',device)\n",
    "    # 损失函数，使用交叉熵损失函数\n",
    "    loss=torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n,batch_count,start=0.0,0.0,0,0,time.time()\n",
    "        for X,y in train_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y)\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 反向传播\n",
    "            l.backward()\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 更新损失和正确率\n",
    "            train_l_sum+=l.cpu().item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1) == y ).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "            batch_count+=1\n",
    "        # 测试集上的正确率\n",
    "        test_acc=evaluate_accuracy(test_iter,net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "        %(epoch+1,train_l_sum/batch_count,train_acc_sum/n,test_acc,time.time()-start))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率，迭代次数\n",
    "lr,num_epochs=0.001,5\n",
    "# 优化器，更新参数\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training on  cpu\n",
      "epoch 1, loss 1.8744, train acc 0.309, test acc 0.573, time 19.7 sec\n",
      "epoch 2, loss 0.9330, train acc 0.649, test acc 0.697, time 18.9 sec\n",
      "epoch 3, loss 0.7458, train acc 0.724, test acc 0.729, time 19.1 sec\n",
      "epoch 4, loss 0.6667, train acc 0.743, test acc 0.746, time 19.7 sec\n",
      "epoch 5, loss 0.6143, train acc 0.760, test acc 0.752, time 20.6 sec\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "train(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}