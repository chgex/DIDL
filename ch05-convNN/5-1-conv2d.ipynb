{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "acd847c392487aabfa03d14b5dc5b2ae233417a28e2d9e43c03b69bccff2848e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 5.1 二维卷积层\n",
    "\n",
    "在卷积层中使用的运算叫做二维互相关运算(cross-correlation)。\n",
    "> 一个二维输入数组和一个二维核（kernel）数组通过互相关运算输出一个二维数组\n",
    "\n",
    "代码实现二维卷积的互相关运算："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def corr2d(X,K):\n",
    "    # X为二维数组，K为二维卷积核\n",
    "    # 卷积核的高和宽\n",
    "    h,w=K.shape\n",
    "    # 卷积运算结果\n",
    "    Y=torch.zeros( (X.shape[0]-h+1,X.shape[1]-w+1) )\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(X[i:i+h,j:j+w]*K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# test\n",
    "X=torch.tensor([\n",
    "    [0,1,2],\n",
    "    [3,4,5],\n",
    "    [6,7,8]\n",
    "])\n",
    "# 卷积核\n",
    "K=torch.tensor([\n",
    "    [0,1],\n",
    "    [2,3]\n",
    "])\n",
    "# 卷积运算（即互相关运算）\n",
    "corr2d(X,K)"
   ]
  },
  {
   "source": [
    "上述的互相关运算，可以被用来构建卷积层。\n",
    "\n",
    "卷积层的模型参数包括了卷积核和标量偏差。\n",
    "\n",
    "训练模型时，先初始化卷积核参数和偏差，然后开始迭代。\n",
    "\n",
    "实现一个卷积层，它的前向计算函数就是corr2d函数加偏量。\n",
    "\n",
    "代码："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_size是卷积核的大小\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super(Conv2D,self).__init__()\n",
    "        # 声明卷积层的参数：卷积核数组和偏差\n",
    "        self.weight=nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias=nn.Parameter(torch.randn(1))\n",
    "    # 定义前向计算函数\n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight)+self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# test\n",
    "# 图像中物体边缘检测\n",
    "\n",
    "X=torch.ones(6,8)\n",
    "X[:,2:6]=0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv kernel\n",
    "\n",
    "K=torch.tensor([\n",
    "    [1,-1]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# 计算\n",
    "Y=corr2d(X,K)\n",
    "Y"
   ]
  },
  {
   "source": [
    "上述示例中，通过卷积运算，图像边界被很好的表达出来了。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 学习核数组\n",
    "\n",
    "步骤：\n",
    "\n",
    "+ 构造一个卷积层\n",
    "\n",
    "+ 初始化卷积层参数\n",
    "\n",
    "+ 开始迭代，使用平方误差比较Y与卷积层的输出\n",
    "\n",
    "+ 计算梯度，更新权重。\n",
    "\n",
    "代码："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epocch 10, loss 0.152\nepocch 20, loss 0.012\nepocch 30, loss 0.001\nepocch 40, loss 0.000\nepocch 50, loss 0.000\n"
     ]
    }
   ],
   "source": [
    "# 构造卷积核，size=(1,2)\n",
    "conv2d=Conv2D(kernel_size=(1,2))\n",
    "\n",
    "# 迭代次数，学习率\n",
    "epoches=50\n",
    "lr=0.01\n",
    "\n",
    "# 开始迭代\n",
    "for i in range(epoches):\n",
    "    Y_hat=conv2d(X)\n",
    "    l=( (Y_hat-Y)**2 ).sum()\n",
    "    l.backward()\n",
    "\n",
    "    # 梯度下降\n",
    "    conv2d.weight.data-=lr*conv2d.weight.grad\n",
    "    conv2d.bias.data-=lr*conv2d.bias.grad\n",
    "\n",
    "    # 梯度清0\n",
    "    conv2d.weight.grad.fill_(0)\n",
    "    conv2d.bias.data.fill_(0)\n",
    "\n",
    "    # print epoch,loss\n",
    "    if (i+1)%10==0:\n",
    "        print('epocch %d, loss %.3f' % (i+1,l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "weight: tensor([[ 0.9994, -0.9994]])\nbias: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print('weight:',conv2d.weight.data)\n",
    "print('bias:',conv2d.bias.data)"
   ]
  },
  {
   "source": [
    "5-1 节小结：\n",
    "\n",
    "+ 二维卷积层的核心运算是二维互相关运算\n",
    "\n",
    "+ 卷积核\\[-1,1\\]可以被用来检测物体边缘\n",
    "\n",
    "+ 可以通过数据，来学习卷积核(的参数)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5-2 填充、步幅\n",
    "\n",
    "卷积层中，输入为$n_h * n_w$ ，卷积窗口是$k_h * k_w$， \n",
    "\n",
    "则卷积输出为$(n_k - k_h +1 )* (n_w - k_w +1)$\n",
    "\n",
    "所以，卷积层的输出形状是由输入形状和卷积核形状所决定的。\n",
    "\n",
    "### 填充\n",
    "\n",
    "指在输入的宽和高的两侧(即数组的外围，围一圈0),填充元素。\n",
    "\n",
    "填充会使得输入的数组，增加宽和高的值。\n",
    "\n",
    "如果在高的两侧填充了$p_h$行，在宽的两侧填充了$p_h$行，那么\n",
    "输出的结果是：$(n_k - k_h +1 +p_h)* (n_w - k_w +1+p_w)$\n",
    "\n",
    "通常，为了使输出保持与输入相同的大小，填充值$p_h=k_h-1$，$p_w=k_w-1$。\n",
    "\n",
    "关于填充：\n",
    "\n",
    "+ 如果$k_h$是奇数，会在高的两侧分别填充$\\frac{p_h}{2}$行，在宽的两侧填充$\\frac{p_w}{2}$行。\n",
    "\n",
    "+ 如果$k_h$是偶数，在输入的顶端一侧填充$\\lceil \\frac{p_h}{2} \\rceil$ 行，而在底端一侧填充$\\lfloor \\frac{p_h}{2} \\rfloor$行。宽的两侧填充同理。 \n",
    "\n",
    "示例：\n",
    "\n",
    "使用torch.nn.Conv2d(),实现填充和卷积。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数，来计算卷积层，\n",
    "# 对输入做填充，使得输出的形状与输入的形状相同\n",
    "\n",
    "def comp_conv2d(conv2d,X):\n",
    "    # (1,1)表示批量大小和通道数\n",
    "    X=X.view( (1,1) + X.shape)\n",
    "    Y=conv2d(X)\n",
    "    # 前两维是批量和通道，在那时不关心，所以排除\n",
    "    return Y.view(Y.shape[2:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 情况一：卷积核的宽和高是相等的\n",
    "\n",
    "# 两侧各填充1行或列。\n",
    "conv2d=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,padding=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# test\n",
    "X=torch.rand(8,8)\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# 情况二：卷积核的宽和高是不等的\n",
    "# (5-1)/2=2,(3-1)/2=1\n",
    "# 所以需要设置padding=(2,1)\n",
    "\n",
    "conv2d=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=(5,3),padding=(2,1))\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "source": [
    "### 步幅\n",
    "\n",
    "卷积核在输入数组的左上方开始滑动，每次滑动的行数和列数称为步幅。\n",
    "\n",
    "如果在输入数组的高上步幅为$s_h$，在输入数组的宽上步幅为$s_w$，则输出的数组的形状为：\n",
    "$$ \n",
    "\\lfloor (n_h - k_h + p_h + s_h)/s_h  \\rfloor *\n",
    "\\lfloor (n_w - k_w + p_w + s_w)/s_w  \\rfloor\n",
    "$$\n",
    "\n",
    "如果输入的数组宽和高能被步幅整除，则输出数组的形状为：\n",
    "$$\n",
    "(n_h/s_h)*(n_w/s_w)\n",
    "$$\n",
    "\n",
    "示例：\n",
    "\n",
    "使用torch.nn.Conv2d函数。参数stride=2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,padding=1,stride=2)\n",
    "\n",
    "# test1\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=(3,5),padding=(0,1),stride=(3,4))\n",
    "\n",
    "# test1\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "source": [
    "### 本节小结\n",
    "\n",
    "+ 填充可以增加输出的高和宽\n",
    "\n",
    "+ 步幅可以减少输出的高和宽。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}