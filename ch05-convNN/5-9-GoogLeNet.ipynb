{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "acd847c392487aabfa03d14b5dc5b2ae233417a28e2d9e43c03b69bccff2848e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 5.9 GoogLeNet\n",
    "\n",
    "关于该网络：\n",
    "\n",
    "+ 首次出现是在2014年ImageNet图像识别比赛中，\n",
    "\n",
    "+ 名字上是向LeNet致敬，但在网络结构上，区别很大，\n",
    "\n",
    "+ GoogLeNet网络的基础块叫Inception,结构如下：\n",
    "\n",
    "![img](https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.9_inception.svg)\n",
    "\n",
    "\n",
    "\n",
    "Inception块，实现代码："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time \n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F \n",
    "import d2l_pytorch as d2l \n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # 4条线路\n",
    "    def __init__(self,in_c,c1,c2,c3,c4):\n",
    "        super(Inception,self).__init__()\n",
    "        # 线路1，共1层，就是最左侧的那条\n",
    "        ## 1*1的卷积层，用来减少通道数\n",
    "        self.p1_1=nn.Conv2d(in_channels=in_c,out_channels=c1,kernel_size=1)\n",
    "        # 线路2，共2层\n",
    "        ## 1*1的卷积层\n",
    "        self.p2_1=nn.Conv2d(in_channels=in_c,out_channels=c2[0],kernel_size=1)\n",
    "        ## 3*3的卷积层\n",
    "        self.p2_2=nn.Conv2d(c2[0],c2[1],kernel_size=3,padding=1)\n",
    "        # 线路3，共2层\n",
    "        ## 1*1的卷积层\n",
    "        self.p3_1=nn.Conv2d(in_c,c3[0],kernel_size=1)\n",
    "        ## 5*5的卷积层\n",
    "        self.p3_2=nn.Conv2d(c3[0],c3[1],kernel_size=5,padding=2)\n",
    "        # 线路4，共2层\n",
    "        ## 3*3的最大池化层\n",
    "        self.p4_1=nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
    "        self.p4_2=nn.Conv2d(in_c,c4,kernel_size=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # 线路1\n",
    "        p1=F.relu(self.p1_1(x))\n",
    "        # 线路2\n",
    "        p2=F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        # 线路3\n",
    "        p3=F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        # 线路4\n",
    "        p4=F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # 将四条线路的输出，在通道维上连结\n",
    "        return torch.cat((p1,p2,p3,p4),dim=1)  "
   ]
  },
  {
   "source": [
    "+ GoogLeNet模型，在主体部分使用5个模块。\n",
    "\n",
    "    每个模块之间使用步幅为2的3\\*3池化层来减小输出的高和宽，\n",
    "\n",
    "    每一个模块使用通道数为7\\*7的卷积层。\n",
    "\n",
    "模块1和模块2如图：\n",
    "\n",
    "<img src=\"https://gitee.com/changyv/md-pic/raw/master/20210317211018.png\" style=\"zoom:50%;\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1=nn.Sequential(\n",
    "    nn.Conv2d(1,64,kernel_size=7,stride=2,padding=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    ")\n",
    "b2=nn.Sequential(\n",
    "    # 1*1的卷积层\n",
    "    nn.Conv2d(64,64,kernel_size=1),\n",
    "    # 3*3的卷积层，将通道数增加3倍\n",
    "    nn.Conv2d(64,192,kernel_size=3,padding=1),\n",
    "    # 池化层\n",
    "    nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    ")"
   ]
  },
  {
   "source": [
    "第3个模块，串联2个完整的Inception块，\n",
    "\n",
    "第一个模块输出通道数为：64+128+32+32=256\n",
    "\n",
    "第二个模块输出通道数为：128+192+96+64=480\n",
    "\n",
    "如图：\n",
    "\n",
    "<img src=\"https://gitee.com/changyv/md-pic/raw/master/20210317212459.png\" alt=\"image-20210317212456643\" style=\"zoom:50%;\" />\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3=nn.Sequential(\n",
    "    Inception(192,64,(96,128),(16,32),32),\n",
    "    Inception(256,128,(128,192),(32,96),64),\n",
    "    nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    ")"
   ]
  },
  {
   "source": [
    "第四个模块，串联了5个Inception块，输出通道数分别为：\n",
    "\n",
    "+ 192+208+48+64=512\n",
    "\n",
    "+ 160+224+64+64=512\n",
    "\n",
    "+ 128+256+64+64=512、\n",
    "\n",
    "+ 112+288+64+64=528\n",
    "\n",
    "+ 256+320+128+128=832"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4 = nn.Sequential(\n",
    "    Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "    Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "    Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "    Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "    Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "source": [
    "第5个模块，串联了2个Inception模块，其输出通道分别为：\n",
    "\n",
    "+ 256+320+128+128=832\n",
    "\n",
    "+ 384+384+128+128=1024\n",
    "\n",
    "第5个模块后面，跟着输出层，输出层使用全局平均池化层，将每个通道的高和宽变为1，最后将输出变为二维数组，后接一个输出个数为类别的全连接层。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5 = nn.Sequential(\n",
    "    Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "    Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "    d2l.GlobalAvgPool2d()\n",
    ")"
   ]
  },
  {
   "source": [
    "输出层"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    b1, b2, b3, b4, b5, \n",
    "    d2l.FlattenLayer(), \n",
    "    nn.Linear(1024, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "out shape: torch.Size([1, 64, 24, 24])\nout shape: torch.Size([1, 192, 12, 12])\nout shape: torch.Size([1, 480, 6, 6])\nout shape: torch.Size([1, 832, 3, 3])\nout shape: torch.Size([1, 1024, 1, 1])\nout shape: torch.Size([1, 1024])\nout shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# 将输入的高和宽从224降到96，简化计算\n",
    "\n",
    "X=torch.rand(1,1,96,96)\n",
    "\n",
    "for blk in net.children():\n",
    "    X=blk(X)\n",
    "    print('out shape:',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据，训练模型\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist_ch05(batch_size,resize=96)\n",
    "\n",
    "lr,num_epochs=0.001,2\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "125/937, loss 2.304\n",
      "epoch 0/2, iter 126/937, loss 2.311\n",
      "epoch 0/2, iter 127/937, loss 2.306\n",
      "epoch 0/2, iter 128/937, loss 2.302\n",
      "epoch 0/2, iter 129/937, loss 2.304\n",
      "epoch 0/2, iter 130/937, loss 2.302\n",
      "epoch 0/2, iter 131/937, loss 2.306\n",
      "epoch 0/2, iter 132/937, loss 2.298\n",
      "epoch 0/2, iter 133/937, loss 2.306\n",
      "epoch 0/2, iter 134/937, loss 2.303\n",
      "epoch 0/2, iter 135/937, loss 2.303\n",
      "epoch 0/2, iter 136/937, loss 2.301\n",
      "epoch 0/2, iter 137/937, loss 2.300\n",
      "epoch 0/2, iter 138/937, loss 2.300\n",
      "epoch 0/2, iter 139/937, loss 2.303\n",
      "epoch 0/2, iter 140/937, loss 2.304\n",
      "epoch 0/2, iter 141/937, loss 2.300\n",
      "epoch 0/2, iter 142/937, loss 2.303\n",
      "epoch 0/2, iter 143/937, loss 2.306\n",
      "epoch 0/2, iter 144/937, loss 2.304\n",
      "epoch 0/2, iter 145/937, loss 2.302\n",
      "epoch 0/2, iter 146/937, loss 2.305\n",
      "epoch 0/2, iter 147/937, loss 2.301\n",
      "epoch 0/2, iter 148/937, loss 2.304\n",
      "epoch 0/2, iter 149/937, loss 2.306\n",
      "epoch 0/2, iter 150/937, loss 2.308\n",
      "epoch 0/2, iter 151/937, loss 2.301\n",
      "epoch 0/2, iter 152/937, loss 2.300\n",
      "epoch 0/2, iter 153/937, loss 2.306\n",
      "epoch 0/2, iter 154/937, loss 2.305\n",
      "epoch 0/2, iter 155/937, loss 2.307\n",
      "epoch 0/2, iter 156/937, loss 2.302\n",
      "epoch 0/2, iter 157/937, loss 2.304\n",
      "epoch 0/2, iter 158/937, loss 2.303\n",
      "epoch 0/2, iter 159/937, loss 2.302\n",
      "epoch 0/2, iter 160/937, loss 2.303\n",
      "epoch 0/2, iter 161/937, loss 2.303\n",
      "epoch 0/2, iter 162/937, loss 2.299\n",
      "epoch 0/2, iter 163/937, loss 2.302\n",
      "epoch 0/2, iter 164/937, loss 2.305\n",
      "epoch 0/2, iter 165/937, loss 2.303\n",
      "epoch 0/2, iter 166/937, loss 2.305\n",
      "epoch 0/2, iter 167/937, loss 2.303\n",
      "epoch 0/2, iter 168/937, loss 2.303\n",
      "epoch 0/2, iter 169/937, loss 2.305\n",
      "epoch 0/2, iter 170/937, loss 2.302\n",
      "epoch 0/2, iter 171/937, loss 2.302\n",
      "epoch 0/2, iter 172/937, loss 2.302\n",
      "epoch 0/2, iter 173/937, loss 2.300\n",
      "epoch 0/2, iter 174/937, loss 2.304\n",
      "epoch 0/2, iter 175/937, loss 2.304\n",
      "epoch 0/2, iter 176/937, loss 2.305\n",
      "epoch 0/2, iter 177/937, loss 2.301\n",
      "epoch 0/2, iter 178/937, loss 2.299\n",
      "epoch 0/2, iter 179/937, loss 2.306\n",
      "epoch 0/2, iter 180/937, loss 2.300\n",
      "epoch 0/2, iter 181/937, loss 2.301\n",
      "epoch 0/2, iter 182/937, loss 2.306\n",
      "epoch 0/2, iter 183/937, loss 2.300\n",
      "epoch 0/2, iter 184/937, loss 2.302\n",
      "epoch 0/2, iter 185/937, loss 2.300\n",
      "epoch 0/2, iter 186/937, loss 2.303\n",
      "epoch 0/2, iter 187/937, loss 2.304\n",
      "epoch 0/2, iter 188/937, loss 2.299\n",
      "epoch 0/2, iter 189/937, loss 2.304\n",
      "epoch 0/2, iter 190/937, loss 2.302\n",
      "epoch 0/2, iter 191/937, loss 2.296\n",
      "epoch 0/2, iter 192/937, loss 2.305\n",
      "epoch 0/2, iter 193/937, loss 2.300\n",
      "epoch 0/2, iter 194/937, loss 2.306\n",
      "epoch 0/2, iter 195/937, loss 2.304\n",
      "epoch 0/2, iter 196/937, loss 2.298\n",
      "epoch 0/2, iter 197/937, loss 2.304\n",
      "epoch 0/2, iter 198/937, loss 2.300\n",
      "epoch 0/2, iter 199/937, loss 2.306\n",
      "epoch 0/2, iter 200/937, loss 2.305\n",
      "epoch 0/2, iter 201/937, loss 2.296\n",
      "epoch 0/2, iter 202/937, loss 2.289\n",
      "epoch 0/2, iter 203/937, loss 2.295\n",
      "epoch 0/2, iter 204/937, loss 2.310\n",
      "epoch 0/2, iter 205/937, loss 2.287\n",
      "epoch 0/2, iter 206/937, loss 2.309\n",
      "epoch 0/2, iter 207/937, loss 2.296\n",
      "epoch 0/2, iter 208/937, loss 2.316\n",
      "epoch 0/2, iter 209/937, loss 2.285\n",
      "epoch 0/2, iter 210/937, loss 2.315\n",
      "epoch 0/2, iter 211/937, loss 2.311\n",
      "epoch 0/2, iter 212/937, loss 2.313\n",
      "epoch 0/2, iter 213/937, loss 2.312\n",
      "epoch 0/2, iter 214/937, loss 2.313\n",
      "epoch 0/2, iter 215/937, loss 2.305\n",
      "epoch 0/2, iter 216/937, loss 2.303\n",
      "epoch 0/2, iter 217/937, loss 2.305\n",
      "epoch 0/2, iter 218/937, loss 2.309\n",
      "epoch 0/2, iter 219/937, loss 2.302\n",
      "epoch 0/2, iter 220/937, loss 2.305\n",
      "epoch 0/2, iter 221/937, loss 2.303\n",
      "epoch 0/2, iter 222/937, loss 2.304\n",
      "epoch 0/2, iter 223/937, loss 2.301\n",
      "epoch 0/2, iter 224/937, loss 2.299\n",
      "epoch 0/2, iter 225/937, loss 2.302\n",
      "epoch 0/2, iter 226/937, loss 2.302\n",
      "epoch 0/2, iter 227/937, loss 2.301\n",
      "epoch 0/2, iter 228/937, loss 2.301\n",
      "epoch 0/2, iter 229/937, loss 2.306\n",
      "epoch 0/2, iter 230/937, loss 2.305\n",
      "epoch 0/2, iter 231/937, loss 2.300\n",
      "epoch 0/2, iter 232/937, loss 2.303\n",
      "epoch 0/2, iter 233/937, loss 2.301\n",
      "epoch 0/2, iter 234/937, loss 2.302\n",
      "epoch 0/2, iter 235/937, loss 2.307\n",
      "epoch 0/2, iter 236/937, loss 2.301\n",
      "epoch 0/2, iter 237/937, loss 2.301\n",
      "epoch 0/2, iter 238/937, loss 2.301\n",
      "epoch 0/2, iter 239/937, loss 2.300\n",
      "epoch 0/2, iter 240/937, loss 2.304\n",
      "epoch 0/2, iter 241/937, loss 2.307\n",
      "epoch 0/2, iter 242/937, loss 2.306\n",
      "epoch 0/2, iter 243/937, loss 2.303\n",
      "epoch 0/2, iter 244/937, loss 2.306\n",
      "epoch 0/2, iter 245/937, loss 2.306\n",
      "epoch 0/2, iter 246/937, loss 2.299\n",
      "epoch 0/2, iter 247/937, loss 2.305\n",
      "epoch 0/2, iter 248/937, loss 2.300\n",
      "epoch 0/2, iter 249/937, loss 2.304\n",
      "epoch 0/2, iter 250/937, loss 2.303\n",
      "epoch 0/2, iter 251/937, loss 2.306\n",
      "epoch 0/2, iter 252/937, loss 2.301\n",
      "epoch 0/2, iter 253/937, loss 2.304\n",
      "epoch 0/2, iter 254/937, loss 2.303\n",
      "epoch 0/2, iter 255/937, loss 2.303\n",
      "epoch 0/2, iter 256/937, loss 2.303\n",
      "epoch 0/2, iter 257/937, loss 2.304\n",
      "epoch 0/2, iter 258/937, loss 2.303\n",
      "epoch 0/2, iter 259/937, loss 2.305\n",
      "epoch 0/2, iter 260/937, loss 2.301\n",
      "epoch 0/2, iter 261/937, loss 2.304\n",
      "epoch 0/2, iter 262/937, loss 2.300\n",
      "epoch 0/2, iter 263/937, loss 2.303\n",
      "epoch 0/2, iter 264/937, loss 2.303\n",
      "epoch 0/2, iter 265/937, loss 2.303\n",
      "epoch 0/2, iter 266/937, loss 2.303\n",
      "epoch 0/2, iter 267/937, loss 2.301\n",
      "epoch 0/2, iter 268/937, loss 2.304\n",
      "epoch 0/2, iter 269/937, loss 2.301\n",
      "epoch 0/2, iter 270/937, loss 2.303\n",
      "epoch 0/2, iter 271/937, loss 2.303\n",
      "epoch 0/2, iter 272/937, loss 2.303\n",
      "epoch 0/2, iter 273/937, loss 2.303\n",
      "epoch 0/2, iter 274/937, loss 2.301\n",
      "epoch 0/2, iter 275/937, loss 2.303\n",
      "epoch 0/2, iter 276/937, loss 2.304\n",
      "epoch 0/2, iter 277/937, loss 2.305\n",
      "epoch 0/2, iter 278/937, loss 2.304\n",
      "epoch 0/2, iter 279/937, loss 2.302\n",
      "epoch 0/2, iter 280/937, loss 2.302\n",
      "epoch 0/2, iter 281/937, loss 2.304\n",
      "epoch 0/2, iter 282/937, loss 2.303\n",
      "epoch 0/2, iter 283/937, loss 2.300\n",
      "epoch 0/2, iter 284/937, loss 2.303\n",
      "epoch 0/2, iter 285/937, loss 2.301\n",
      "epoch 0/2, iter 286/937, loss 2.299\n",
      "epoch 0/2, iter 287/937, loss 2.303\n",
      "epoch 0/2, iter 288/937, loss 2.303\n",
      "epoch 0/2, iter 289/937, loss 2.302\n",
      "epoch 0/2, iter 290/937, loss 2.304\n",
      "epoch 0/2, iter 291/937, loss 2.301\n",
      "epoch 0/2, iter 292/937, loss 2.304\n",
      "epoch 0/2, iter 293/937, loss 2.303\n",
      "epoch 0/2, iter 294/937, loss 2.300\n",
      "epoch 0/2, iter 295/937, loss 2.304\n",
      "epoch 0/2, iter 296/937, loss 2.304\n",
      "epoch 0/2, iter 297/937, loss 2.296\n",
      "epoch 0/2, iter 298/937, loss 2.304\n",
      "epoch 0/2, iter 299/937, loss 2.305\n",
      "epoch 0/2, iter 300/937, loss 2.298\n",
      "epoch 0/2, iter 301/937, loss 2.303\n",
      "epoch 0/2, iter 302/937, loss 2.302\n",
      "epoch 0/2, iter 303/937, loss 2.301\n",
      "epoch 0/2, iter 304/937, loss 2.300\n",
      "epoch 0/2, iter 305/937, loss 2.297\n",
      "epoch 0/2, iter 306/937, loss 2.309\n",
      "epoch 0/2, iter 307/937, loss 2.301\n",
      "epoch 0/2, iter 308/937, loss 2.300\n",
      "epoch 0/2, iter 309/937, loss 2.299\n",
      "epoch 0/2, iter 310/937, loss 2.301\n",
      "epoch 0/2, iter 311/937, loss 2.309\n",
      "epoch 0/2, iter 312/937, loss 2.300\n",
      "epoch 0/2, iter 313/937, loss 2.304\n",
      "epoch 0/2, iter 314/937, loss 2.307\n",
      "epoch 0/2, iter 315/937, loss 2.309\n",
      "epoch 0/2, iter 316/937, loss 2.310\n",
      "epoch 0/2, iter 317/937, loss 2.301\n",
      "epoch 0/2, iter 318/937, loss 2.306\n",
      "epoch 0/2, iter 319/937, loss 2.308\n",
      "epoch 0/2, iter 320/937, loss 2.307\n",
      "epoch 0/2, iter 321/937, loss 2.299\n",
      "epoch 0/2, iter 322/937, loss 2.304\n",
      "epoch 0/2, iter 323/937, loss 2.298\n",
      "epoch 0/2, iter 324/937, loss 2.300\n",
      "epoch 0/2, iter 325/937, loss 2.301\n",
      "epoch 0/2, iter 326/937, loss 2.302\n",
      "epoch 0/2, iter 327/937, loss 2.305\n",
      "epoch 0/2, iter 328/937, loss 2.306\n",
      "epoch 0/2, iter 329/937, loss 2.302\n",
      "epoch 0/2, iter 330/937, loss 2.306\n",
      "epoch 0/2, iter 331/937, loss 2.302\n",
      "epoch 0/2, iter 332/937, loss 2.301\n",
      "epoch 0/2, iter 333/937, loss 2.303\n",
      "epoch 0/2, iter 334/937, loss 2.303\n",
      "epoch 0/2, iter 335/937, loss 2.302\n",
      "epoch 0/2, iter 336/937, loss 2.304\n",
      "epoch 0/2, iter 337/937, loss 2.304\n",
      "epoch 0/2, iter 338/937, loss 2.304\n",
      "epoch 0/2, iter 339/937, loss 2.302\n",
      "epoch 0/2, iter 340/937, loss 2.305\n",
      "epoch 0/2, iter 341/937, loss 2.304\n",
      "epoch 0/2, iter 342/937, loss 2.303\n",
      "epoch 0/2, iter 343/937, loss 2.300\n",
      "epoch 0/2, iter 344/937, loss 2.304\n",
      "epoch 0/2, iter 345/937, loss 2.306\n",
      "epoch 0/2, iter 346/937, loss 2.305\n",
      "epoch 0/2, iter 347/937, loss 2.302\n",
      "epoch 0/2, iter 348/937, loss 2.302\n",
      "epoch 0/2, iter 349/937, loss 2.302\n",
      "epoch 0/2, iter 350/937, loss 2.305\n",
      "epoch 0/2, iter 351/937, loss 2.303\n",
      "epoch 0/2, iter 352/937, loss 2.304\n",
      "epoch 0/2, iter 353/937, loss 2.305\n",
      "epoch 0/2, iter 354/937, loss 2.303\n",
      "epoch 0/2, iter 355/937, loss 2.305\n",
      "epoch 0/2, iter 356/937, loss 2.301\n",
      "epoch 0/2, iter 357/937, loss 2.301\n",
      "epoch 0/2, iter 358/937, loss 2.301\n",
      "epoch 0/2, iter 359/937, loss 2.302\n",
      "epoch 0/2, iter 360/937, loss 2.304\n",
      "epoch 0/2, iter 361/937, loss 2.304\n",
      "epoch 0/2, iter 362/937, loss 2.302\n",
      "epoch 0/2, iter 363/937, loss 2.302\n",
      "epoch 0/2, iter 364/937, loss 2.302\n",
      "epoch 0/2, iter 365/937, loss 2.300\n",
      "epoch 0/2, iter 366/937, loss 2.304\n",
      "epoch 0/2, iter 367/937, loss 2.303\n",
      "epoch 0/2, iter 368/937, loss 2.302\n",
      "epoch 0/2, iter 369/937, loss 2.303\n",
      "epoch 0/2, iter 370/937, loss 2.304\n",
      "epoch 0/2, iter 371/937, loss 2.305\n",
      "epoch 0/2, iter 372/937, loss 2.300\n",
      "epoch 0/2, iter 373/937, loss 2.304\n",
      "epoch 0/2, iter 374/937, loss 2.303\n",
      "epoch 0/2, iter 375/937, loss 2.304\n",
      "epoch 0/2, iter 376/937, loss 2.306\n",
      "epoch 0/2, iter 377/937, loss 2.303\n",
      "epoch 0/2, iter 378/937, loss 2.302\n",
      "epoch 0/2, iter 379/937, loss 2.304\n",
      "epoch 0/2, iter 380/937, loss 2.302\n",
      "epoch 0/2, iter 381/937, loss 2.303\n",
      "epoch 0/2, iter 382/937, loss 2.302\n",
      "epoch 0/2, iter 383/937, loss 2.302\n",
      "epoch 0/2, iter 384/937, loss 2.301\n",
      "epoch 0/2, iter 385/937, loss 2.303\n",
      "epoch 0/2, iter 386/937, loss 2.298\n",
      "epoch 0/2, iter 387/937, loss 2.301\n",
      "epoch 0/2, iter 388/937, loss 2.302\n",
      "epoch 0/2, iter 389/937, loss 2.300\n",
      "epoch 0/2, iter 390/937, loss 2.304\n",
      "epoch 0/2, iter 391/937, loss 2.298\n",
      "epoch 0/2, iter 392/937, loss 2.303\n",
      "epoch 0/2, iter 393/937, loss 2.303\n",
      "epoch 0/2, iter 394/937, loss 2.303\n",
      "epoch 0/2, iter 395/937, loss 2.303\n",
      "epoch 0/2, iter 396/937, loss 2.298\n",
      "epoch 0/2, iter 397/937, loss 2.307\n",
      "epoch 0/2, iter 398/937, loss 2.305\n",
      "epoch 0/2, iter 399/937, loss 2.300\n",
      "epoch 0/2, iter 400/937, loss 2.304\n",
      "epoch 0/2, iter 401/937, loss 2.304\n",
      "epoch 0/2, iter 402/937, loss 2.304\n",
      "epoch 0/2, iter 403/937, loss 2.304\n",
      "epoch 0/2, iter 404/937, loss 2.302\n",
      "epoch 0/2, iter 405/937, loss 2.301\n",
      "epoch 0/2, iter 406/937, loss 2.304\n",
      "epoch 0/2, iter 407/937, loss 2.299\n",
      "epoch 0/2, iter 408/937, loss 2.303\n",
      "epoch 0/2, iter 409/937, loss 2.301\n",
      "epoch 0/2, iter 410/937, loss 2.304\n",
      "epoch 0/2, iter 411/937, loss 2.304\n",
      "epoch 0/2, iter 412/937, loss 2.298\n",
      "epoch 0/2, iter 413/937, loss 2.303\n",
      "epoch 0/2, iter 414/937, loss 2.303\n",
      "epoch 0/2, iter 415/937, loss 2.302\n",
      "epoch 0/2, iter 416/937, loss 2.307\n",
      "epoch 0/2, iter 417/937, loss 2.306\n",
      "epoch 0/2, iter 418/937, loss 2.304\n",
      "epoch 0/2, iter 419/937, loss 2.306\n",
      "epoch 0/2, iter 420/937, loss 2.309\n",
      "epoch 0/2, iter 421/937, loss 2.305\n",
      "epoch 0/2, iter 422/937, loss 2.302\n",
      "epoch 0/2, iter 423/937, loss 2.302\n",
      "epoch 0/2, iter 424/937, loss 2.303\n",
      "epoch 0/2, iter 425/937, loss 2.310\n",
      "epoch 0/2, iter 426/937, loss 2.303\n",
      "epoch 0/2, iter 427/937, loss 2.302\n",
      "epoch 0/2, iter 428/937, loss 2.302\n",
      "epoch 0/2, iter 429/937, loss 2.300\n",
      "epoch 0/2, iter 430/937, loss 2.305\n",
      "epoch 0/2, iter 431/937, loss 2.302\n",
      "epoch 0/2, iter 432/937, loss 2.301\n",
      "epoch 0/2, iter 433/937, loss 2.302\n",
      "epoch 0/2, iter 434/937, loss 2.303\n",
      "epoch 0/2, iter 435/937, loss 2.307\n",
      "epoch 0/2, iter 436/937, loss 2.302\n",
      "epoch 0/2, iter 437/937, loss 2.303\n",
      "epoch 0/2, iter 438/937, loss 2.304\n",
      "epoch 0/2, iter 439/937, loss 2.306\n",
      "epoch 0/2, iter 440/937, loss 2.299\n",
      "epoch 0/2, iter 441/937, loss 2.303\n",
      "epoch 0/2, iter 442/937, loss 2.305\n",
      "epoch 0/2, iter 443/937, loss 2.301\n",
      "epoch 0/2, iter 444/937, loss 2.300\n",
      "epoch 0/2, iter 445/937, loss 2.302\n",
      "epoch 0/2, iter 446/937, loss 2.302\n",
      "epoch 0/2, iter 447/937, loss 2.301\n",
      "epoch 0/2, iter 448/937, loss 2.302\n",
      "epoch 0/2, iter 449/937, loss 2.301\n",
      "epoch 0/2, iter 450/937, loss 2.299\n",
      "epoch 0/2, iter 451/937, loss 2.305\n",
      "epoch 0/2, iter 452/937, loss 2.300\n",
      "epoch 0/2, iter 453/937, loss 2.299\n",
      "epoch 0/2, iter 454/937, loss 2.305\n",
      "epoch 0/2, iter 455/937, loss 2.305\n",
      "epoch 0/2, iter 456/937, loss 2.302\n",
      "epoch 0/2, iter 457/937, loss 2.301\n",
      "epoch 0/2, iter 458/937, loss 2.300\n",
      "epoch 0/2, iter 459/937, loss 2.299\n",
      "epoch 0/2, iter 460/937, loss 2.303\n",
      "epoch 0/2, iter 461/937, loss 2.300\n",
      "epoch 0/2, iter 462/937, loss 2.305\n",
      "epoch 0/2, iter 463/937, loss 2.306\n",
      "epoch 0/2, iter 464/937, loss 2.304\n",
      "epoch 0/2, iter 465/937, loss 2.301\n",
      "epoch 0/2, iter 466/937, loss 2.301\n",
      "epoch 0/2, iter 467/937, loss 2.301\n",
      "epoch 0/2, iter 468/937, loss 2.305\n",
      "epoch 0/2, iter 469/937, loss 2.298\n",
      "epoch 0/2, iter 470/937, loss 2.304\n",
      "epoch 0/2, iter 471/937, loss 2.305\n",
      "epoch 0/2, iter 472/937, loss 2.305\n",
      "epoch 0/2, iter 473/937, loss 2.301\n",
      "epoch 0/2, iter 474/937, loss 2.300\n",
      "epoch 0/2, iter 475/937, loss 2.300\n",
      "epoch 0/2, iter 476/937, loss 2.304\n",
      "epoch 0/2, iter 477/937, loss 2.302\n",
      "epoch 0/2, iter 478/937, loss 2.300\n",
      "epoch 0/2, iter 479/937, loss 2.306\n",
      "epoch 0/2, iter 480/937, loss 2.306\n",
      "epoch 0/2, iter 481/937, loss 2.303\n",
      "epoch 0/2, iter 482/937, loss 2.302\n",
      "epoch 0/2, iter 483/937, loss 2.306\n",
      "epoch 0/2, iter 484/937, loss 2.307\n",
      "epoch 0/2, iter 485/937, loss 2.302\n",
      "epoch 0/2, iter 486/937, loss 2.304\n",
      "epoch 0/2, iter 487/937, loss 2.307\n",
      "epoch 0/2, iter 488/937, loss 2.300\n",
      "epoch 0/2, iter 489/937, loss 2.301\n",
      "epoch 0/2, iter 490/937, loss 2.302\n",
      "epoch 0/2, iter 491/937, loss 2.300\n",
      "epoch 0/2, iter 492/937, loss 2.305\n",
      "epoch 0/2, iter 493/937, loss 2.307\n",
      "epoch 0/2, iter 494/937, loss 2.305\n",
      "epoch 0/2, iter 495/937, loss 2.301\n",
      "epoch 0/2, iter 496/937, loss 2.304\n",
      "epoch 0/2, iter 497/937, loss 2.305\n",
      "epoch 0/2, iter 498/937, loss 2.306\n",
      "epoch 0/2, iter 499/937, loss 2.307\n",
      "epoch 0/2, iter 500/937, loss 2.306\n",
      "epoch 0/2, iter 501/937, loss 2.301\n",
      "epoch 0/2, iter 502/937, loss 2.306\n",
      "epoch 0/2, iter 503/937, loss 2.301\n",
      "epoch 0/2, iter 504/937, loss 2.301\n",
      "epoch 0/2, iter 505/937, loss 2.302\n",
      "epoch 0/2, iter 506/937, loss 2.301\n",
      "epoch 0/2, iter 507/937, loss 2.303\n",
      "epoch 0/2, iter 508/937, loss 2.303\n",
      "epoch 0/2, iter 509/937, loss 2.304\n",
      "epoch 0/2, iter 510/937, loss 2.303\n",
      "epoch 0/2, iter 511/937, loss 2.305\n",
      "epoch 0/2, iter 512/937, loss 2.301\n",
      "epoch 0/2, iter 513/937, loss 2.304\n",
      "epoch 0/2, iter 514/937, loss 2.304\n",
      "epoch 0/2, iter 515/937, loss 2.303\n",
      "epoch 0/2, iter 516/937, loss 2.302\n",
      "epoch 0/2, iter 517/937, loss 2.302\n",
      "epoch 0/2, iter 518/937, loss 2.301\n",
      "epoch 0/2, iter 519/937, loss 2.302\n",
      "epoch 0/2, iter 520/937, loss 2.301\n",
      "epoch 0/2, iter 521/937, loss 2.302\n",
      "epoch 0/2, iter 522/937, loss 2.304\n",
      "epoch 0/2, iter 523/937, loss 2.302\n",
      "epoch 0/2, iter 524/937, loss 2.301\n",
      "epoch 0/2, iter 525/937, loss 2.304\n",
      "epoch 0/2, iter 526/937, loss 2.302\n",
      "epoch 0/2, iter 527/937, loss 2.301\n",
      "epoch 0/2, iter 528/937, loss 2.307\n",
      "epoch 0/2, iter 529/937, loss 2.307\n",
      "epoch 0/2, iter 530/937, loss 2.302\n",
      "epoch 0/2, iter 531/937, loss 2.303\n",
      "epoch 0/2, iter 532/937, loss 2.302\n",
      "epoch 0/2, iter 533/937, loss 2.304\n",
      "epoch 0/2, iter 534/937, loss 2.303\n",
      "epoch 0/2, iter 535/937, loss 2.304\n",
      "epoch 0/2, iter 536/937, loss 2.303\n",
      "epoch 0/2, iter 537/937, loss 2.304\n",
      "epoch 0/2, iter 538/937, loss 2.303\n",
      "epoch 0/2, iter 539/937, loss 2.307\n",
      "epoch 0/2, iter 540/937, loss 2.301\n",
      "epoch 0/2, iter 541/937, loss 2.303\n",
      "epoch 0/2, iter 542/937, loss 2.303\n",
      "epoch 0/2, iter 543/937, loss 2.302\n",
      "epoch 0/2, iter 544/937, loss 2.302\n",
      "epoch 0/2, iter 545/937, loss 2.303\n",
      "epoch 0/2, iter 546/937, loss 2.304\n",
      "epoch 0/2, iter 547/937, loss 2.302\n",
      "epoch 0/2, iter 548/937, loss 2.305\n",
      "epoch 0/2, iter 549/937, loss 2.303\n",
      "epoch 0/2, iter 550/937, loss 2.301\n",
      "epoch 0/2, iter 551/937, loss 2.301\n",
      "epoch 0/2, iter 552/937, loss 2.302\n",
      "epoch 0/2, iter 553/937, loss 2.306\n",
      "epoch 0/2, iter 554/937, loss 2.302\n",
      "epoch 0/2, iter 555/937, loss 2.304\n",
      "epoch 0/2, iter 556/937, loss 2.303\n",
      "epoch 0/2, iter 557/937, loss 2.303\n",
      "epoch 0/2, iter 558/937, loss 2.302\n",
      "epoch 0/2, iter 559/937, loss 2.302\n",
      "epoch 0/2, iter 560/937, loss 2.304\n",
      "epoch 0/2, iter 561/937, loss 2.302\n",
      "epoch 0/2, iter 562/937, loss 2.303\n",
      "epoch 0/2, iter 563/937, loss 2.305\n",
      "epoch 0/2, iter 564/937, loss 2.301\n",
      "epoch 0/2, iter 565/937, loss 2.304\n",
      "epoch 0/2, iter 566/937, loss 2.303\n",
      "epoch 0/2, iter 567/937, loss 2.301\n",
      "epoch 0/2, iter 568/937, loss 2.302\n",
      "epoch 0/2, iter 569/937, loss 2.303\n",
      "epoch 0/2, iter 570/937, loss 2.303\n",
      "epoch 0/2, iter 571/937, loss 2.303\n",
      "epoch 0/2, iter 572/937, loss 2.301\n",
      "epoch 0/2, iter 573/937, loss 2.302\n",
      "epoch 0/2, iter 574/937, loss 2.303\n",
      "epoch 0/2, iter 575/937, loss 2.302\n",
      "epoch 0/2, iter 576/937, loss 2.305\n",
      "epoch 0/2, iter 577/937, loss 2.302\n",
      "epoch 0/2, iter 578/937, loss 2.304\n",
      "epoch 0/2, iter 579/937, loss 2.300\n",
      "epoch 0/2, iter 580/937, loss 2.303\n",
      "epoch 0/2, iter 581/937, loss 2.304\n",
      "epoch 0/2, iter 582/937, loss 2.302\n",
      "epoch 0/2, iter 583/937, loss 2.303\n",
      "epoch 0/2, iter 584/937, loss 2.301\n",
      "epoch 0/2, iter 585/937, loss 2.303\n",
      "epoch 0/2, iter 586/937, loss 2.302\n",
      "epoch 0/2, iter 587/937, loss 2.303\n",
      "epoch 0/2, iter 588/937, loss 2.300\n",
      "epoch 0/2, iter 589/937, loss 2.302\n",
      "epoch 0/2, iter 590/937, loss 2.301\n",
      "epoch 0/2, iter 591/937, loss 2.302\n",
      "epoch 0/2, iter 592/937, loss 2.303\n",
      "epoch 0/2, iter 593/937, loss 2.302\n",
      "epoch 0/2, iter 594/937, loss 2.299\n",
      "epoch 0/2, iter 595/937, loss 2.301\n",
      "epoch 0/2, iter 596/937, loss 2.305\n",
      "epoch 0/2, iter 597/937, loss 2.304\n",
      "epoch 0/2, iter 598/937, loss 2.301\n",
      "epoch 0/2, iter 599/937, loss 2.303\n",
      "epoch 0/2, iter 600/937, loss 2.301\n",
      "epoch 0/2, iter 601/937, loss 2.305\n",
      "epoch 0/2, iter 602/937, loss 2.303\n",
      "epoch 0/2, iter 603/937, loss 2.302\n",
      "epoch 0/2, iter 604/937, loss 2.302\n",
      "epoch 0/2, iter 605/937, loss 2.302\n",
      "epoch 0/2, iter 606/937, loss 2.302\n",
      "epoch 0/2, iter 607/937, loss 2.302\n",
      "epoch 0/2, iter 608/937, loss 2.302\n",
      "epoch 0/2, iter 609/937, loss 2.302\n",
      "epoch 0/2, iter 610/937, loss 2.301\n",
      "epoch 0/2, iter 611/937, loss 2.302\n",
      "epoch 0/2, iter 612/937, loss 2.302\n",
      "epoch 0/2, iter 613/937, loss 2.304\n",
      "epoch 0/2, iter 614/937, loss 2.305\n",
      "epoch 0/2, iter 615/937, loss 2.302\n",
      "epoch 0/2, iter 616/937, loss 2.302\n",
      "epoch 0/2, iter 617/937, loss 2.303\n",
      "epoch 0/2, iter 618/937, loss 2.305\n",
      "epoch 0/2, iter 619/937, loss 2.303\n",
      "epoch 0/2, iter 620/937, loss 2.302\n",
      "epoch 0/2, iter 621/937, loss 2.302\n",
      "epoch 0/2, iter 622/937, loss 2.303\n",
      "epoch 0/2, iter 623/937, loss 2.301\n",
      "epoch 0/2, iter 624/937, loss 2.301\n",
      "epoch 0/2, iter 625/937, loss 2.302\n",
      "epoch 0/2, iter 626/937, loss 2.303\n",
      "epoch 0/2, iter 627/937, loss 2.301\n",
      "epoch 0/2, iter 628/937, loss 2.302\n",
      "epoch 0/2, iter 629/937, loss 2.303\n",
      "epoch 0/2, iter 630/937, loss 2.305\n",
      "epoch 0/2, iter 631/937, loss 2.305\n",
      "epoch 0/2, iter 632/937, loss 2.300\n",
      "epoch 0/2, iter 633/937, loss 2.304\n",
      "epoch 0/2, iter 634/937, loss 2.304\n",
      "epoch 0/2, iter 635/937, loss 2.301\n",
      "epoch 0/2, iter 636/937, loss 2.302\n",
      "epoch 0/2, iter 637/937, loss 2.302\n",
      "epoch 0/2, iter 638/937, loss 2.305\n",
      "epoch 0/2, iter 639/937, loss 2.303\n",
      "epoch 0/2, iter 640/937, loss 2.302\n",
      "epoch 0/2, iter 641/937, loss 2.305\n",
      "epoch 0/2, iter 642/937, loss 2.305\n",
      "epoch 0/2, iter 643/937, loss 2.305\n",
      "epoch 0/2, iter 644/937, loss 2.303\n",
      "epoch 0/2, iter 645/937, loss 2.303\n",
      "epoch 0/2, iter 646/937, loss 2.302\n",
      "epoch 0/2, iter 647/937, loss 2.303\n",
      "epoch 0/2, iter 648/937, loss 2.302\n",
      "epoch 0/2, iter 649/937, loss 2.305\n",
      "epoch 0/2, iter 650/937, loss 2.302\n",
      "epoch 0/2, iter 651/937, loss 2.303\n",
      "epoch 0/2, iter 652/937, loss 2.303\n",
      "epoch 0/2, iter 653/937, loss 2.304\n",
      "epoch 0/2, iter 654/937, loss 2.300\n",
      "epoch 0/2, iter 655/937, loss 2.300\n",
      "epoch 0/2, iter 656/937, loss 2.301\n",
      "epoch 0/2, iter 657/937, loss 2.304\n",
      "epoch 0/2, iter 658/937, loss 2.301\n",
      "epoch 0/2, iter 659/937, loss 2.303\n",
      "epoch 0/2, iter 660/937, loss 2.301\n",
      "epoch 0/2, iter 661/937, loss 2.304\n",
      "epoch 0/2, iter 662/937, loss 2.303\n",
      "epoch 0/2, iter 663/937, loss 2.305\n",
      "epoch 0/2, iter 664/937, loss 2.305\n",
      "epoch 0/2, iter 665/937, loss 2.301\n",
      "epoch 0/2, iter 666/937, loss 2.302\n",
      "epoch 0/2, iter 667/937, loss 2.301\n",
      "epoch 0/2, iter 668/937, loss 2.302\n",
      "epoch 0/2, iter 669/937, loss 2.304\n",
      "epoch 0/2, iter 670/937, loss 2.303\n",
      "epoch 0/2, iter 671/937, loss 2.302\n",
      "epoch 0/2, iter 672/937, loss 2.302\n",
      "epoch 0/2, iter 673/937, loss 2.306\n",
      "epoch 0/2, iter 674/937, loss 2.301\n",
      "epoch 0/2, iter 675/937, loss 2.303\n",
      "epoch 0/2, iter 676/937, loss 2.303\n",
      "epoch 0/2, iter 677/937, loss 2.304\n",
      "epoch 0/2, iter 678/937, loss 2.304\n",
      "epoch 0/2, iter 679/937, loss 2.304\n",
      "epoch 0/2, iter 680/937, loss 2.305\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "d2l.train_ch05(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs)"
   ]
  },
  {
   "source": [
    "## 小结\n",
    "\n",
    "+ Inception有4个并行的子网络，使用不同窗口的卷积层和最大池化层来并行的抽取信息，使用1\\*1的卷积层减少通道数，\n",
    "\n",
    "+ GoogLeNet将都哦个Inception块与其它块串联起来，每个Inception块的通道分配数的比值，实在ImageNet上大量实验获得，\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}