{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "acd847c392487aabfa03d14b5dc5b2ae233417a28e2d9e43c03b69bccff2848e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 基于VGG-16的Fast RCNN网络\n",
    "\n",
    "Fast RCNN主干网络基于VGG16，做了一定的修改：将最后一层池化层，改为RoI池化层，并在全连接层之后，增加了两个平行网络。\n",
    "\n",
    "VGG16网络结构图如下：\n",
    "\n",
    "<img src=\"./vgg16-architecture.png\" style=\"width:300;height:300px;\">\n",
    "\n",
    "\n",
    "Fast RCNN加入了ROI 池化层和 2个平行网络，结构如下图：\n",
    "<img src=\"./fastrcnn-architecture.png\" style=\"width:300;height:300px;\">\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision.models as models \n",
    "from torch import nn,optim\n",
    "\n",
    "import utils\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "source": [
    "## 定义RoI pooling layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class RoIPool(nn.Module):\n",
    "    def __init__(self,output_size=(7,7)):\n",
    "        super(RoIPool,self).__init__()\n",
    "        # 自适应池化\n",
    "        self.roi_Pool=nn.AdaptiveMaxPool2d(output_size)\n",
    "        self.size=output_size\n",
    "    \n",
    "    def forward(self,feature_map,rois,roi_idxs):\n",
    "        assert feature_map.dim()==4,'should 4d: (n.c,h,w)'\n",
    "        n=rois.shape[0]\n",
    "        _,c,h,w=feature_map.size()\n",
    "        x1,y1,x2,y2=rois[:,0],rois[:,1],rois[:,2],rois[:,3]\n",
    "        # BN层之后，范围为[0,1]，恢复到原大小\n",
    "        x1=np.floor(x1 * w).astype(int)\n",
    "        y1=np.floor(y1 * h).astype(int)\n",
    "        x2=np.ceil(x2 * w).astype(int)\n",
    "        y2=np.ceil(y2 * h).astype(int)\n",
    "\n",
    "        # 保存所有ROI，经过ROI池化层处理，得到的固定尺寸的roi特征图\n",
    "        res=[]\n",
    "        # n个ROI\n",
    "        for i in range(n):\n",
    "            # roi索引号和roi坐标相对应\n",
    "            img=feature_map[ roi_idxs[i] ].unsqueeze(0)\n",
    "            # 参数：batch,chaanels,h,w\n",
    "            img=img[:,:,y1[i]:y2[i],x1[i]:x2[i]]\n",
    "            # 对roi进行自适应卷积，输出固定尺寸的特征图\n",
    "            img=self.roi_Pool(img)\n",
    "            # 保存该roi的特征图\n",
    "            res.append(img)\n",
    "        # 按照维度，将所有roi的特征图，进行连结，输出n*h*w，n为特征图的个数， w和h为超参数，默认为7,7\n",
    "        return torch.cat(res,dim=0)"
   ]
  },
  {
   "source": [
    "w,h=images.size(2),images.size(3)\n",
    "        n=rois.shape[0]\n",
    "        x1,y1,x2,y2=rois[:,0],rois[:,1],rois[:,2],rois[:,3]\n",
    "        x1 = np.floor(x1 * w).astype(int)\n",
    "        x2 = np.ceil(x2 * w).astype(int)\n",
    "        y1 = np.floor(y1 * h).astype(int)\n",
    "        y2 = np.ceil(y2 * h).astype(int)\n",
    "        \n",
    "        res = []\n",
    "        for i in range(n):\n",
    "            img = images[roi_idx[i]].unsqueeze(0)\n",
    "            img = img[:, :, y1[i]:y2[i], x1[i]:x2[i]]\n",
    "            img = self.maxpool(img)\n",
    "            res.append(img)\n",
    "        res = torch.cat(res, dim=0)\n",
    "        return res"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 定义Fast RCNN网络\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "加载torchvision.models库中的vgg16模型，\n",
    "\n",
    "预训练为true: pretrained=true"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16=models.vgg16(pretrained=True)"
   ]
  },
  {
   "source": [
    "feature=nn.Sequential(*list(vgg16.features.children())[:-1])\n",
    "feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastRcnn(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(FastRcnn,self).__init__()\n",
    "        # 去掉 vgg16 features最后一个最大池化层，其余部分不变\n",
    "        self.feature=nn.Sequential(*list(vgg16.features.children())[:-1])\n",
    "        \n",
    "        # 添加RoI最大池化层\n",
    "        self.roiPool=RoIPool(output_size=(7,7))\n",
    "        \n",
    "        # 去掉 VGG16 全连接层的最后一层,其余部分不变\n",
    "        self.fc=nn.Sequential(*list(vgg16.classifier.children())[:-1])\n",
    "        \n",
    "        # 两个平行分支\n",
    "        # +1，是背景类\n",
    "        self.clss=nn.Linear(4096,num_classes+1)\n",
    "        self.bbox=nn.Linear(4096,(num_classes+1) * 4)\n",
    "    \n",
    "    def forward(self,x,rois,roi_idxs):\n",
    "        \n",
    "        x=self.feature(x)\n",
    "        x=self.roiPool(x,rois,roi_idxs)\n",
    "        # no grad\n",
    "        x=x.detach()\n",
    "        # 展平\n",
    "        x=x.view(1,-1)\n",
    "        x=self.fc(x)\n",
    "        # 2个平行分支\n",
    "        clss=self.clss(x)\n",
    "        bbox=self.bbox(x).view(-1,num_classes+1,4)\n",
    "        return clss,bbox"
   ]
  },
  {
   "source": [
    "计算维度"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=nn.Sequential(*list(vgg16.features.children())[:-1])\n",
    "        \n",
    "roiPool=RoIPool(output_size=(7,7))\n",
    "\n",
    "fc=nn.Sequential(*list(vgg16.classifier.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = torch.Tensor(1, 3, 224, 224)\n",
    "_r = np.array([[0., 0., 1., 1.]])\n",
    "_ri = np.array([0])\n",
    "\n",
    "# _x = fc(roiPool( feature(_x), _r, _ri).view(1, -1))\n",
    "# _x.size()  #  torch.Size([1, 4096])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 512, 14, 14])\ntorch.Size([1, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out=feature(_x)\n",
    "print(out.shape)\n",
    "\n",
    "out=roiPool( out, _r, _ri)\n",
    "print(out.shape)\n",
    "\n",
    "out=fc(out.view(1,-1))\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out=fc(out.view(1,-1))\n",
    "\n",
    "out.view(1,-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FastRcnn(\n  (feature): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n  )\n  (roiPool): RoIPool(\n    (roi_Pool): AdaptiveMaxPool2d(output_size=(7, 7))\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n  )\n  (clss): Linear(in_features=4096, out_features=11, bias=True)\n  (bbox): Linear(in_features=4096, out_features=44, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "net = FastRcnn()\n",
    "print(net)"
   ]
  },
  {
   "source": [
    "定义多任务损失函数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 loc 损失函数\n",
    "# 计算 预测出的边界框 和 真值边界框 之间\n",
    "\n",
    "class SmoothL1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmoothL1Loss, self).__init__()\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        res = self.smoothL1(preds - targets)\n",
    "        return torch.sum(res)\n",
    "\n",
    "    def smoothL1(self, x):\n",
    "        if torch.abs(x) < 1:\n",
    "            return 0.5 * torch.pow(x, 2)\n",
    "        else:\n",
    "            return torch.abs(x) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiTaskLoss(probs,bbox,labels,gt_bbox):\n",
    "    # 超参数，控制loc损失和cls损失，对总loss的贡献\n",
    "    lamb=1\n",
    "    # 分类\n",
    "    clss=nn.CrossEntropyLoss()\n",
    "    # 定位\n",
    "    loca=SmoothL1Loss()\n",
    "    \n",
    "    # 分类损失\n",
    "    loss_sc = clss(probs, labels)\n",
    "    \n",
    "    lbl = labels.view(-1, 1, 1).expand(labels.size(0), 1, 4)\n",
    "    # 不计算背景类\n",
    "    mask = (labels != 0).float().view(-1, 1).expand(labels.size(0), 4)\n",
    "    \n",
    "    # 定位损失\n",
    "    loss_loc = loca(bbox.gather(1, lbl).squeeze(1) * mask, gt_bbox * mask)\n",
    "    \n",
    "    # 总的损失\n",
    "    loss = loss_sc + lamb * loss_loc\n",
    "    \n",
    "    return loss, loss_sc, loss_loc"
   ]
  },
  {
   "source": [
    "优化器"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.nn.modules.container.Sequential"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}